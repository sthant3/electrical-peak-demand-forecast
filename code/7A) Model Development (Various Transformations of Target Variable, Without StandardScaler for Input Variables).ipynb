{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Development with Various Transformations of Target Variable (Shortened Version)\n",
    "\n",
    "This script trains and evaluates models using different transformations of the target variable, without using StandardScaler for input variables.\n",
    "\n",
    "Note: This is a shortened version that does not include feature importances or detailed fold performance information. \n",
    "For the entire code, please view the file \n",
    "'7A) Model Development (Various Transformations of Target Variable, Without StandardScaler for Input Variables)' in the full-code folder.\n",
    "\n",
    "Data source: \n",
    "- Preprocessed data: '6) daily_consumption_data_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "df = pd.read_csv('6) daily_consumption_data_full.csv', parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorisation of input variables\n",
    "weather_features = [\n",
    "    'temp_max_today', 'humidity_min_today', 'humidity_max_today', 'windspeed_max_today', 'precip_sum_today', 'solarradiation_sum_today',\n",
    "    'humidity_at_peak_consumption_today', 'windspeed_at_peak_consumption_today', 'precip_at_peak_consumption_today', \n",
    "    'solarradiation_at_peak_consumption_today', 'temp_range_today', 'windspeed_min_today'\n",
    "]\n",
    "\n",
    "temporal_features = [\n",
    "    'is_winter', 'is_summer', 'is_autumn', 'is_weekend', 'is_holiday', 'day_of_week_sin', \n",
    "    'day_of_week_cos', 'week_of_month_sin', 'week_of_month_cos'\n",
    "]\n",
    "\n",
    "consumption_features = [\n",
    "    'consumption_sum_today', 'consumption_peak_today', 'consumption_min_today', 'prev_day_peak', 'same_day_last_week_peak', \n",
    "    'avg_peak_3d', 'avg_peak_7d', 'max_peak_7d', 'max_peak_3d'\n",
    "]\n",
    "\n",
    "household_features = [\n",
    "    'household_size', 'male_occupants', 'female_occupants', 'count_children', 'ownership_owned', \n",
    "    'ownership_rented', 'ownership_other', 'work_from_home', 'housing_house', 'housing_apartment', \n",
    "    'count_rooms', 'electric_central_heating', 'heating_manual_boiler', 'heating_thermostatic_valves', \n",
    "    'heating_auto_set_times', 'heating_auto_temp_control', 'heating_not_sure', 'uses_electric_heater'\n",
    "]\n",
    "\n",
    "pricing_features = [\n",
    "    'prop_low_price', 'prop_high_price', 'tariff_at_peak_consumption_today'\n",
    "]\n",
    "\n",
    "attitudinal_and_behavioural_features = [\n",
    "    'interest_in_renewable_energy', 'interest_in_microgeneration', 'climate_change_concern', \n",
    "    'lifestyle_environment', 'smart_meter_bill_understanding', 'smart_meter_consumption_understanding'\n",
    "]\n",
    "\n",
    "appliance_features = [\n",
    "    'washing_machine_fixed_schedule', 'tumble_dryer_fixed_schedule', 'dishwasher_fixed_schedule', \n",
    "    'immersion_water_heater_fixed_schedule', 'electric_oven_fixed_schedule', 'electric_hob_fixed_schedule', \n",
    "    'ironing_fixed_schedule', 'electric_shower_fixed_schedule', 'kettle_fixed_schedule', 'lighting_fixed_schedule', \n",
    "    'electric_heater_fixed_schedule', 'washer-dryer_combined_timer_use', 'washing_machine_timer_use', \n",
    "    'tumble_dryer_timer_use', 'dishwasher_timer_use', 'electric_space_heating_timer_use', \n",
    "    'washer-dryer_combined_ownership', 'washing_machine_ownership', 'tumble_dryer_ownership', 'dishwasher_ownership', \n",
    "    'electric_space_heating_ownership', 'count_low_efficiency_bulbs', 'total_refrigeration_units', \n",
    "    'count_cooking_appliances', 'count_laundry_appliances', 'count_kitchen_appliances', \n",
    "    'count_heating_water_appliances', 'count_entertainment_devices', 'count_computing_devices', 'count_tv', \n",
    "    'tv_energy_score'\n",
    "]\n",
    "\n",
    "# Define feature sets for models\n",
    "model_1_features = temporal_features + consumption_features\n",
    "model_2_features = model_1_features + weather_features\n",
    "model_3_features = model_2_features + household_features + pricing_features + attitudinal_and_behavioural_features + appliance_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply different transformations as the target variable is skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'log_consumption_peak_next_day': np.log1p,\n",
    "    'sqrt_consumption_peak_next_day': np.sqrt,\n",
    "    'cbrt_consumption_peak_next_day': np.cbrt\n",
    "}\n",
    "\n",
    "for new_col, func in transformations.items():\n",
    "    df[new_col] = func(df['consumption_peak_next_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models using each transformation of the target variable, consumption_peak_next_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': randint(100, 3000),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.29),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1)\n",
    "}\n",
    "\n",
    "# Define date ranges for folds\n",
    "# Considering we only have 2013 data, we will define the folds as the following and use December as the test set\n",
    "folds = [\n",
    "    ('2013-01-08', '2013-08-31', '2013-09-01', '2013-09-30'),\n",
    "    ('2013-01-08', '2013-09-30', '2013-10-01', '2013-10-31'),\n",
    "    ('2013-01-08', '2013-10-31', '2013-11-01', '2013-11-30')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(features, df, folds, param_grid, model_name):\n",
    "    def create_dataset(df, start_date, end_date):\n",
    "        mask = (df['date'] >= pd.to_datetime(start_date)) & (df['date'] <= pd.to_datetime(end_date))\n",
    "        X = df.loc[mask, features]\n",
    "        y = df.loc[mask, ['consumption_peak_next_day', 'log_consumption_peak_next_day', \n",
    "                          'sqrt_consumption_peak_next_day', 'cbrt_consumption_peak_next_day']]\n",
    "        return X, y\n",
    "\n",
    "    def calculate_metrics(y_true, y_pred, transformation='consumption_peak_next_day'):\n",
    "        if transformation == 'log_consumption_peak_next_day':\n",
    "            y_true, y_pred = np.expm1(y_true), np.expm1(y_pred)\n",
    "        elif transformation == 'sqrt_consumption_peak_next_day':\n",
    "            y_true, y_pred = y_true ** 2, y_pred ** 2\n",
    "        elif transformation == 'cbrt_consumption_peak_next_day':\n",
    "            y_true, y_pred = y_true ** 3, y_pred ** 3\n",
    "        \n",
    "        mae = np.mean(np.abs(y_true - y_pred))\n",
    "        \n",
    "        non_zero = (y_true != 0)\n",
    "        mape = np.mean(np.abs((y_true[non_zero] - y_pred[non_zero]) / y_true[non_zero])) * 100\n",
    "        \n",
    "        wape = np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true)) * 100\n",
    "        \n",
    "        r2 = r2_score(y_true, y_pred)\n",
    "        \n",
    "        return mae, mape, wape, r2\n",
    "    \n",
    "    def wape_score(y_true, y_pred):\n",
    "        return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "    wape_scorer = make_scorer(wape_score, greater_is_better=False)\n",
    "\n",
    "    results = {target: {'mae_scores_train': [], 'mape_scores_train': [], 'wape_scores_train': [], 'r2_scores_train': [],\n",
    "                        'mae_scores_val': [], 'mape_scores_val': [], 'wape_scores_val': [], 'r2_scores_val': [],\n",
    "                        'best_params': []} \n",
    "               for target in ['consumption_peak_next_day', 'log_consumption_peak_next_day', \n",
    "                              'sqrt_consumption_peak_next_day', 'cbrt_consumption_peak_next_day']}\n",
    "\n",
    "    for fold, (train_start, train_end, val_start, val_end) in enumerate(folds, 1):\n",
    "        X_train, y_train = create_dataset(df, train_start, train_end)\n",
    "        X_val, y_val = create_dataset(df, val_start, val_end)\n",
    "        \n",
    "        tscv = TimeSeriesSplit(n_splits=3)\n",
    "        \n",
    "        for target in ['consumption_peak_next_day', 'log_consumption_peak_next_day', \n",
    "                       'sqrt_consumption_peak_next_day', 'cbrt_consumption_peak_next_day']:\n",
    "            \n",
    "            model = XGBRegressor(objective='reg:squarederror', n_jobs=-1, enable_categorical=True)\n",
    "            random_search = RandomizedSearchCV(model, param_distributions=param_grid, \n",
    "                                               n_iter=100, cv=tscv.split(X_train), \n",
    "                                               scoring=wape_scorer, \n",
    "                                               n_jobs=-1, random_state=1)\n",
    "            random_search.fit(X_train, y_train[target])\n",
    "            \n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "            results[target]['best_params'].append(best_params)\n",
    "            \n",
    "            train_predictions = best_model.predict(X_train)\n",
    "            train_mae, train_mape, train_wape, train_r2 = calculate_metrics(y_train[target], train_predictions, target)\n",
    "            results[target]['mae_scores_train'].append(train_mae)\n",
    "            results[target]['mape_scores_train'].append(train_mape)\n",
    "            results[target]['wape_scores_train'].append(train_wape)\n",
    "            results[target]['r2_scores_train'].append(train_r2)\n",
    "            \n",
    "            val_predictions = best_model.predict(X_val)\n",
    "            val_mae, val_mape, val_wape, val_r2 = calculate_metrics(y_val[target], val_predictions, target)\n",
    "            results[target]['mae_scores_val'].append(val_mae)\n",
    "            results[target]['mape_scores_val'].append(val_mape)\n",
    "            results[target]['wape_scores_val'].append(val_wape)\n",
    "            results[target]['r2_scores_val'].append(val_r2)\n",
    "\n",
    "    print(f\"\\n--- Results for {model_name} ---\")\n",
    "    for target in ['consumption_peak_next_day', 'log_consumption_peak_next_day', \n",
    "                   'sqrt_consumption_peak_next_day', 'cbrt_consumption_peak_next_day']:\n",
    "        print(f\"\\nResults for {target}:\")\n",
    "        print(f\"Average Training MAE: {np.mean(results[target]['mae_scores_train']):.4f}\")\n",
    "        print(f\"Average Training MAPE: {np.mean(results[target]['mape_scores_train']):.4f}%\")\n",
    "        print(f\"Average Training WAPE: {np.mean(results[target]['wape_scores_train']):.4f}%\")\n",
    "        print(f\"Average Training R²: {np.mean(results[target]['r2_scores_train']):.4f}\")\n",
    "        print(f\"Average Validation MAE: {np.mean(results[target]['mae_scores_val']):.4f}\")\n",
    "        print(f\"Average Validation MAPE: {np.mean(results[target]['mape_scores_val']):.4f}%\")\n",
    "        print(f\"Average Validation WAPE: {np.mean(results[target]['wape_scores_val']):.4f}%\")\n",
    "        print(f\"Average Validation R²: {np.mean(results[target]['r2_scores_val']):.4f}\")\n",
    "\n",
    "    test_start = '2013-12-01'\n",
    "    test_end = '2013-12-30'\n",
    "\n",
    "    X_train_final, y_train_final = create_dataset(df, df['date'].min(), pd.to_datetime(test_start) - pd.Timedelta(days=1))\n",
    "    X_test, y_test = create_dataset(df, test_start, test_end)\n",
    "\n",
    "    final_models = {}\n",
    "    test_metrics = {}\n",
    "\n",
    "    print(\"\\n--- Test Metrics ---\")\n",
    "    for target in ['consumption_peak_next_day', 'log_consumption_peak_next_day', \n",
    "                   'sqrt_consumption_peak_next_day', 'cbrt_consumption_peak_next_day']:\n",
    "        best_params = results[target]['best_params'][np.argmin(results[target]['wape_scores_val'])]\n",
    "        final_model = XGBRegressor(**best_params, enable_categorical=True)\n",
    "        final_model.fit(X_train_final, y_train_final[target])\n",
    "\n",
    "        test_predictions = final_model.predict(X_test)\n",
    "        test_mae, test_mape, test_wape, test_r2 = calculate_metrics(y_test[target], test_predictions, target)\n",
    "        print(f\"\\nTest metrics for {target}:\")\n",
    "        print(f\"MAE: {test_mae:.4f}\")\n",
    "        print(f\"MAPE: {test_mape:.4f}%\")\n",
    "        print(f\"WAPE: {test_wape:.4f}%\")\n",
    "        print(f\"R²: {test_r2:.4f}\")\n",
    "\n",
    "        final_models[target] = final_model\n",
    "        test_metrics[target] = {'mae': test_mae, 'mape': test_mape, 'wape': test_wape, 'r2': test_r2}\n",
    "\n",
    "    return final_models, test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run and compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results for Model 1 ---\n",
      "\n",
      "Results for consumption_peak_next_day:\n",
      "Average Training MAE: 0.3335\n",
      "Average Training MAPE: 56.9102%\n",
      "Average Training WAPE: 29.9714%\n",
      "Average Training R²: 0.6999\n",
      "Average Validation MAE: 0.3579\n",
      "Average Validation MAPE: 62.1932%\n",
      "Average Validation WAPE: 31.9314%\n",
      "Average Validation R²: 0.5990\n",
      "\n",
      "Results for log_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3383\n",
      "Average Training MAPE: 51.1096%\n",
      "Average Training WAPE: 30.4043%\n",
      "Average Training R²: 0.6679\n",
      "Average Validation MAE: 0.3535\n",
      "Average Validation MAPE: 53.8475%\n",
      "Average Validation WAPE: 31.5326%\n",
      "Average Validation R²: 0.5924\n",
      "\n",
      "Results for sqrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3336\n",
      "Average Training MAPE: 45.6123%\n",
      "Average Training WAPE: 29.9862%\n",
      "Average Training R²: 0.6772\n",
      "Average Validation MAE: 0.3522\n",
      "Average Validation MAPE: 48.4540%\n",
      "Average Validation WAPE: 31.4192%\n",
      "Average Validation R²: 0.5928\n",
      "\n",
      "Results for cbrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3275\n",
      "Average Training MAPE: 41.3433%\n",
      "Average Training WAPE: 29.4321%\n",
      "Average Training R²: 0.6828\n",
      "Average Validation MAE: 0.3512\n",
      "Average Validation MAPE: 45.4303%\n",
      "Average Validation WAPE: 31.3295%\n",
      "Average Validation R²: 0.5887\n",
      "\n",
      "--- Test Metrics ---\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "MAE: 0.3936\n",
      "MAPE: 65.0182%\n",
      "WAPE: 30.7272%\n",
      "R²: 0.6441\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "MAE: 0.3865\n",
      "MAPE: 57.1380%\n",
      "WAPE: 30.1728%\n",
      "R²: 0.6418\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "MAE: 0.3860\n",
      "MAPE: 50.8990%\n",
      "WAPE: 30.1404%\n",
      "R²: 0.6411\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "MAE: 0.3835\n",
      "MAPE: 48.6112%\n",
      "WAPE: 29.9416%\n",
      "R²: 0.6408\n",
      "\n",
      "--- Results for Model 2 ---\n",
      "\n",
      "Results for consumption_peak_next_day:\n",
      "Average Training MAE: 0.3449\n",
      "Average Training MAPE: 60.2357%\n",
      "Average Training WAPE: 30.9981%\n",
      "Average Training R²: 0.6730\n",
      "Average Validation MAE: 0.3596\n",
      "Average Validation MAPE: 64.3568%\n",
      "Average Validation WAPE: 32.0763%\n",
      "Average Validation R²: 0.5983\n",
      "\n",
      "Results for log_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3381\n",
      "Average Training MAPE: 51.1458%\n",
      "Average Training WAPE: 30.3833%\n",
      "Average Training R²: 0.6683\n",
      "Average Validation MAE: 0.3540\n",
      "Average Validation MAPE: 54.0451%\n",
      "Average Validation WAPE: 31.5749%\n",
      "Average Validation R²: 0.5920\n",
      "\n",
      "Results for sqrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3382\n",
      "Average Training MAPE: 47.0358%\n",
      "Average Training WAPE: 30.3979%\n",
      "Average Training R²: 0.6654\n",
      "Average Validation MAE: 0.3529\n",
      "Average Validation MAPE: 48.8451%\n",
      "Average Validation WAPE: 31.4689%\n",
      "Average Validation R²: 0.5926\n",
      "\n",
      "Results for cbrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3269\n",
      "Average Training MAPE: 41.5989%\n",
      "Average Training WAPE: 29.3752%\n",
      "Average Training R²: 0.6841\n",
      "Average Validation MAE: 0.3518\n",
      "Average Validation MAPE: 45.7585%\n",
      "Average Validation WAPE: 31.3826%\n",
      "Average Validation R²: 0.5881\n",
      "\n",
      "--- Test Metrics ---\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "MAE: 0.3977\n",
      "MAPE: 65.4365%\n",
      "WAPE: 31.0477%\n",
      "R²: 0.6361\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "MAE: 0.3912\n",
      "MAPE: 56.9194%\n",
      "WAPE: 30.5467%\n",
      "R²: 0.6314\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "MAE: 0.3887\n",
      "MAPE: 52.0977%\n",
      "WAPE: 30.3478%\n",
      "R²: 0.6353\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "MAE: 0.3865\n",
      "MAPE: 49.6987%\n",
      "WAPE: 30.1740%\n",
      "R²: 0.6340\n",
      "\n",
      "--- Results for Model 3 ---\n",
      "\n",
      "Results for consumption_peak_next_day:\n",
      "Average Training MAE: 0.2925\n",
      "Average Training MAPE: 49.6180%\n",
      "Average Training WAPE: 26.2958%\n",
      "Average Training R²: 0.7766\n",
      "Average Validation MAE: 0.3463\n",
      "Average Validation MAPE: 60.6031%\n",
      "Average Validation WAPE: 30.9041%\n",
      "Average Validation R²: 0.6259\n",
      "\n",
      "Results for log_consumption_peak_next_day:\n",
      "Average Training MAE: 0.2784\n",
      "Average Training MAPE: 40.0420%\n",
      "Average Training WAPE: 25.0203%\n",
      "Average Training R²: 0.7804\n",
      "Average Validation MAE: 0.3401\n",
      "Average Validation MAPE: 51.0203%\n",
      "Average Validation WAPE: 30.3430%\n",
      "Average Validation R²: 0.6221\n",
      "\n",
      "Results for sqrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.2768\n",
      "Average Training MAPE: 36.6860%\n",
      "Average Training WAPE: 24.8766%\n",
      "Average Training R²: 0.7838\n",
      "Average Validation MAE: 0.3389\n",
      "Average Validation MAPE: 47.0815%\n",
      "Average Validation WAPE: 30.2286%\n",
      "Average Validation R²: 0.6232\n",
      "\n",
      "Results for cbrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.2909\n",
      "Average Training MAPE: 35.9172%\n",
      "Average Training WAPE: 26.1439%\n",
      "Average Training R²: 0.7512\n",
      "Average Validation MAE: 0.3389\n",
      "Average Validation MAPE: 43.8581%\n",
      "Average Validation WAPE: 30.2270%\n",
      "Average Validation R²: 0.6163\n",
      "\n",
      "--- Test Metrics ---\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "MAE: 0.3835\n",
      "MAPE: 63.5759%\n",
      "WAPE: 29.9428%\n",
      "R²: 0.6593\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "MAE: 0.3771\n",
      "MAPE: 55.8346%\n",
      "WAPE: 29.4439%\n",
      "R²: 0.6563\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "MAE: 0.3758\n",
      "MAPE: 51.4472%\n",
      "WAPE: 29.3411%\n",
      "R²: 0.6575\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "MAE: 0.3743\n",
      "MAPE: 48.8103%\n",
      "WAPE: 29.2278%\n",
      "R²: 0.6547\n",
      "\n",
      "--- Results for Model 4 (Only Top 15 Features from Model 3) ---\n",
      "\n",
      "Results for consumption_peak_next_day:\n",
      "Average Training MAE: 0.3333\n",
      "Average Training MAPE: 56.4717%\n",
      "Average Training WAPE: 29.9526%\n",
      "Average Training R²: 0.6991\n",
      "Average Validation MAE: 0.3552\n",
      "Average Validation MAPE: 61.5259%\n",
      "Average Validation WAPE: 31.6985%\n",
      "Average Validation R²: 0.6034\n",
      "\n",
      "Results for log_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3141\n",
      "Average Training MAPE: 45.8714%\n",
      "Average Training WAPE: 28.2353%\n",
      "Average Training R²: 0.7180\n",
      "Average Validation MAE: 0.3505\n",
      "Average Validation MAPE: 52.1509%\n",
      "Average Validation WAPE: 31.2625%\n",
      "Average Validation R²: 0.5975\n",
      "\n",
      "Results for sqrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3194\n",
      "Average Training MAPE: 43.1705%\n",
      "Average Training WAPE: 28.7015%\n",
      "Average Training R²: 0.7072\n",
      "Average Validation MAE: 0.3498\n",
      "Average Validation MAPE: 47.4752%\n",
      "Average Validation WAPE: 31.1984%\n",
      "Average Validation R²: 0.5967\n",
      "\n",
      "Results for cbrt_consumption_peak_next_day:\n",
      "Average Training MAE: 0.3278\n",
      "Average Training MAPE: 41.9470%\n",
      "Average Training WAPE: 29.4606%\n",
      "Average Training R²: 0.6818\n",
      "Average Validation MAE: 0.3493\n",
      "Average Validation MAPE: 44.6718%\n",
      "Average Validation WAPE: 31.1543%\n",
      "Average Validation R²: 0.5918\n",
      "\n",
      "--- Test Metrics ---\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "MAE: 0.3880\n",
      "MAPE: 60.1537%\n",
      "WAPE: 30.2910%\n",
      "R²: 0.6491\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "MAE: 0.3831\n",
      "MAPE: 53.2186%\n",
      "WAPE: 29.9093%\n",
      "R²: 0.6436\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "MAE: 0.3820\n",
      "MAPE: 48.9536%\n",
      "WAPE: 29.8232%\n",
      "R²: 0.6444\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "MAE: 0.3818\n",
      "MAPE: 46.5135%\n",
      "WAPE: 29.8116%\n",
      "R²: 0.6402\n",
      "\n",
      "--- Model Comparison ---\n",
      "\n",
      "Model 1:\n",
      "Number of features: 18\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "  MAE: 0.3936\n",
      "  MAPE: 65.0182%\n",
      "  WAPE: 30.7272%\n",
      "  R²: 0.6441\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "  MAE: 0.3865\n",
      "  MAPE: 57.1380%\n",
      "  WAPE: 30.1728%\n",
      "  R²: 0.6418\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "  MAE: 0.3860\n",
      "  MAPE: 50.8990%\n",
      "  WAPE: 30.1404%\n",
      "  R²: 0.6411\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "  MAE: 0.3835\n",
      "  MAPE: 48.6112%\n",
      "  WAPE: 29.9416%\n",
      "  R²: 0.6408\n",
      "\n",
      "Model 2:\n",
      "Number of features: 30\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "  MAE: 0.3977\n",
      "  MAPE: 65.4365%\n",
      "  WAPE: 31.0477%\n",
      "  R²: 0.6361\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "  MAE: 0.3912\n",
      "  MAPE: 56.9194%\n",
      "  WAPE: 30.5467%\n",
      "  R²: 0.6314\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "  MAE: 0.3887\n",
      "  MAPE: 52.0977%\n",
      "  WAPE: 30.3478%\n",
      "  R²: 0.6353\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "  MAE: 0.3865\n",
      "  MAPE: 49.6987%\n",
      "  WAPE: 30.1740%\n",
      "  R²: 0.6340\n",
      "\n",
      "Model 3:\n",
      "Number of features: 88\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "  MAE: 0.3835\n",
      "  MAPE: 63.5759%\n",
      "  WAPE: 29.9428%\n",
      "  R²: 0.6593\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "  MAE: 0.3771\n",
      "  MAPE: 55.8346%\n",
      "  WAPE: 29.4439%\n",
      "  R²: 0.6563\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "  MAE: 0.3758\n",
      "  MAPE: 51.4472%\n",
      "  WAPE: 29.3411%\n",
      "  R²: 0.6575\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "  MAE: 0.3743\n",
      "  MAPE: 48.8103%\n",
      "  WAPE: 29.2278%\n",
      "  R²: 0.6547\n",
      "\n",
      "Model 4:\n",
      "Number of features: 15\n",
      "\n",
      "Test metrics for consumption_peak_next_day:\n",
      "  MAE: 0.3880\n",
      "  MAPE: 60.1537%\n",
      "  WAPE: 30.2910%\n",
      "  R²: 0.6491\n",
      "\n",
      "Test metrics for log_consumption_peak_next_day:\n",
      "  MAE: 0.3831\n",
      "  MAPE: 53.2186%\n",
      "  WAPE: 29.9093%\n",
      "  R²: 0.6436\n",
      "\n",
      "Test metrics for sqrt_consumption_peak_next_day:\n",
      "  MAE: 0.3820\n",
      "  MAPE: 48.9536%\n",
      "  WAPE: 29.8232%\n",
      "  R²: 0.6444\n",
      "\n",
      "Test metrics for cbrt_consumption_peak_next_day:\n",
      "  MAE: 0.3818\n",
      "  MAPE: 46.5135%\n",
      "  WAPE: 29.8116%\n",
      "  R²: 0.6402\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store results\n",
    "all_results = {}\n",
    "\n",
    "# Run models 1 to 3\n",
    "for i, features in enumerate([model_1_features, model_2_features, model_3_features], 1):\n",
    "    model_name = f\"Model {i}\"\n",
    "    final_models, test_metrics = run_model(features, df, folds, param_grid, model_name)\n",
    "    all_results[model_name] = {\n",
    "        'features': features,\n",
    "        'test_metrics': test_metrics,\n",
    "    }\n",
    "\n",
    "# Train model 4, which only uses the top 15 features from model 3\n",
    "model_4_features = [feature for feature, importance in \n",
    "                    sorted(zip(model_3_features, final_models['consumption_peak_next_day'].feature_importances_), \n",
    "                           key=lambda x: x[1], reverse=True)[:15]]\n",
    "model_4, metrics_4 = run_model(model_4_features, df, folds, param_grid, \"Model 4 (Only Top 15 Features from Model 3)\")\n",
    "\n",
    "all_results[\"Model 4\"] = {\n",
    "    'features': model_4_features,\n",
    "    'test_metrics': metrics_4,\n",
    "}\n",
    "\n",
    "# Compare the models\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "for model_name, results in all_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"Number of features: {len(results['features'])}\")\n",
    "    for target, metrics in results['test_metrics'].items():\n",
    "        print(f\"\\nTest metrics for {target}:\")\n",
    "        print(f\"  MAE: {metrics['mae']:.4f}\")\n",
    "        print(f\"  MAPE: {metrics['mape']:.4f}%\")\n",
    "        print(f\"  WAPE: {metrics['wape']:.4f}%\")\n",
    "        print(f\"  R²: {metrics['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the best hyperparameters for the cube root transformation of Model 4 (the optimal model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best tuned hyperparameters for cube root transformation of Model 4:\n",
      "n_estimators: 1270\n",
      "max_depth: 8\n",
      "learning_rate: 0.018057171166114286\n",
      "subsample: 0.7390362533589154\n",
      "colsample_bytree: 0.7292919068542159\n",
      "min_child_weight: 5\n",
      "gamma: 0.05667096138379524\n",
      "reg_alpha: 0.45240482674645155\n",
      "reg_lambda: 0.4500867470007611\n"
     ]
    }
   ],
   "source": [
    "best_params_cbrt_model4 = model_4['cbrt_consumption_peak_next_day'].get_params()\n",
    "# Filter only the tuned hyperparameters\n",
    "tuned_params = ['n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'min_child_weight', 'gamma', 'reg_alpha', 'reg_lambda']\n",
    "\n",
    "print(\"\\nBest tuned hyperparameters for cube root transformation of Model 4:\")\n",
    "for param in tuned_params:\n",
    "    print(f\"{param}: {best_params_cbrt_model4[param]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
