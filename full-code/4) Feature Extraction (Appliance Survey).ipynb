{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "# In our case, performance isn't affected by much, so let's suppress the warning\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "\n",
    "# Load the survey data\n",
    "df_survey = pd.read_csv('2) responses_to_selected_survey_questions_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will first process the demographic information (Q18-34) and perform consistency checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine most common age range\n",
    "def most_common_age_range(df):\n",
    "    all_ages = [age for row in df[age_columns].values for age in row if pd.notna(age)]\n",
    "    return max(set(all_ages), key=all_ages.count) if all_ages else np.nan\n",
    "\n",
    "# Function to count age groups\n",
    "def count_age_group(row, age_ranges):\n",
    "    return sum(1 for age in row if age in age_ranges)\n",
    "\n",
    "# Process Q18: household size, Q19-26: Gender, Q27-34: Age\n",
    "df_survey['household_size'] = pd.to_numeric(df_survey['Q18'], errors='coerce')\n",
    "gender_columns = [f'Q{i}' for i in range(19, 27)]\n",
    "age_columns = [f'Q{i}' for i in range(27, 35)]\n",
    "\n",
    "df_survey['male_occupants'] = df_survey[gender_columns].apply(lambda row: (row == 'Male').sum(), axis=1)\n",
    "df_survey['female_occupants'] = df_survey[gender_columns].apply(lambda row: (row == 'Female').sum(), axis=1)\n",
    "\n",
    "child_age_ranges = ['0-4', '5-11', '11-May', '12-15', '15-Dec', '16-17']\n",
    "adult_age_ranges = ['18-24', '25-34', '35-44', '45-54', '55-64', '65-74', '75 or older']\n",
    "\n",
    "df_survey['count_children'] = df_survey[age_columns].apply(lambda row: count_age_group(row, child_age_ranges), axis=1)\n",
    "df_survey['count_adult'] = df_survey[age_columns].apply(lambda row: count_age_group(row, adult_age_ranges), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency Checks:\n",
      "Households where size != sum of male and female occupants: 45\n",
      "Households where size != sum of children and adults: 33\n",
      "Households where sum of genders != sum of age groups: 32\n",
      "Households where no adults: 7\n",
      "Households where more than 8 members: 0\n",
      "Households where more children than total size: 0\n",
      "Households where all members are children: 1\n",
      "\n",
      "Detailed information for inconsistent households:\n",
      "    Household_id  household_size  male_occupants  female_occupants  \\\n",
      "6          D0010             NaN               0                 0   \n",
      "14         D0020             NaN               0                 1   \n",
      "26         D0038             2.0               3                 1   \n",
      "47         D0086             5.0               3                 1   \n",
      "57         D0104             NaN               1                 1   \n",
      "58         D0105             NaN               0                 0   \n",
      "80         D0143             3.0               1                 1   \n",
      "107        D0191             1.0               0                 0   \n",
      "110        D0195             NaN               1                 1   \n",
      "150        D0261             2.0               1                 0   \n",
      "156        D0270             1.0               0                 0   \n",
      "165        D0282             1.0               0                 0   \n",
      "167        D0284             1.0               0                 0   \n",
      "175        D0300             NaN               0                 0   \n",
      "177        D0302             1.0               1                 1   \n",
      "202        D0336             NaN               1                 1   \n",
      "253        D0426             1.0               0                 0   \n",
      "284        D0482             1.0               0                 0   \n",
      "292        D0498             NaN               0                 1   \n",
      "298        D0511             NaN               2                 1   \n",
      "329        D0564             NaN               0                 1   \n",
      "332        D0569             NaN               1                 1   \n",
      "333        D0570             1.0               0                 0   \n",
      "335        D0573             1.0               0                 0   \n",
      "346        D0594             1.0               0                 0   \n",
      "366        D0621             NaN               1                 0   \n",
      "388        D0659             2.0               0                 0   \n",
      "396        D0671             NaN               0                 1   \n",
      "404        D0683             NaN               1                 1   \n",
      "408        D0688             1.0               0                 0   \n",
      "411        D0691             1.0               0                 0   \n",
      "429        D0724             2.0               0                 0   \n",
      "433        D0732             NaN               1                 0   \n",
      "463        D0784             NaN               0                 1   \n",
      "465        D0787             2.0               0                 0   \n",
      "476        D0804             1.0               0                 0   \n",
      "510        D0863             1.0               0                 0   \n",
      "523        D0882             NaN               0                 0   \n",
      "527        D0887             2.0               0                 1   \n",
      "540        D0910             1.0               0                 0   \n",
      "545        D0917             3.0               0                 0   \n",
      "551        D0927             1.0               0                 0   \n",
      "562        D0955             1.0               1                 1   \n",
      "584        D0993             2.0               2                 1   \n",
      "588        D0998             NaN               2                 0   \n",
      "7          D0011             2.0               0                 2   \n",
      "27         D0039             1.0               1                 0   \n",
      "89         D0163             2.0               1                 1   \n",
      "115        D0200             1.0               1                 0   \n",
      "301        D0515             2.0               1                 1   \n",
      "489        D0829             2.0               1                 1   \n",
      "537        D0906             2.0               1                 1   \n",
      "601        D1017             2.0               1                 1   \n",
      "\n",
      "     count_children  count_adult  \n",
      "6                 0            1  \n",
      "14                0            1  \n",
      "26                2            2  \n",
      "47                0            5  \n",
      "57                0            2  \n",
      "58                0            1  \n",
      "80                0            3  \n",
      "107               0            1  \n",
      "110               0            2  \n",
      "150               0            1  \n",
      "156               0            1  \n",
      "165               0            1  \n",
      "167               0            1  \n",
      "175               0            1  \n",
      "177               0            2  \n",
      "202               0            2  \n",
      "253               0            1  \n",
      "284               0            1  \n",
      "292               0            1  \n",
      "298               2            1  \n",
      "329               0            1  \n",
      "332               0            2  \n",
      "333               0            1  \n",
      "335               0            1  \n",
      "346               0            1  \n",
      "366               0            1  \n",
      "388               0            2  \n",
      "396               0            1  \n",
      "404               1            1  \n",
      "408               0            1  \n",
      "411               0            1  \n",
      "429               0            2  \n",
      "433               0            1  \n",
      "463               0            1  \n",
      "465               0            2  \n",
      "476               0            0  \n",
      "510               0            1  \n",
      "523               0            2  \n",
      "527               0            1  \n",
      "540               0            1  \n",
      "545               0            3  \n",
      "551               0            1  \n",
      "562               0            2  \n",
      "584               0            3  \n",
      "588               0            2  \n",
      "7                 0            0  \n",
      "27                0            0  \n",
      "89                0            0  \n",
      "115               0            0  \n",
      "301               0            1  \n",
      "489               0            1  \n",
      "537               0            0  \n",
      "601               0            0  \n"
     ]
    }
   ],
   "source": [
    "# Function to perform consistency checks for demographics information\n",
    "def consistency_checks(df):\n",
    "    checks = {\n",
    "        \"size != sum of male and female occupants\": df['household_size'] != (df['male_occupants'] + df['female_occupants']),\n",
    "        \"size != sum of children and adults\": df['household_size'] != (df['count_children'] + df['count_adult']),\n",
    "        \"sum of genders != sum of age groups\": (df['male_occupants'] + df['female_occupants']) != (df['count_children'] + df['count_adult']),\n",
    "        \"no adults\": df['count_adult'] == 0,\n",
    "        \"more than 8 members\": df['household_size'] > 8,\n",
    "        \"more children than total size\": df['count_children'] > df['household_size'],\n",
    "        \"all members are children\": (df['count_children'] == df['household_size']) & (df['household_size'] > 0)\n",
    "    }\n",
    "    \n",
    "    print(\"Consistency Checks:\")\n",
    "    for description, condition in checks.items():\n",
    "        inconsistent = df[condition]\n",
    "        print(f\"Households where {description}: {len(inconsistent)}\")\n",
    "    \n",
    "    all_inconsistent = pd.concat([df[condition] for condition in checks.values()]).drop_duplicates()\n",
    "    print(\"\\nDetailed information for inconsistent households:\")\n",
    "    print(all_inconsistent[['Household_id', 'household_size', 'male_occupants', 'female_occupants', 'count_children', 'count_adult']])\n",
    "\n",
    "# Run initial consistency checks\n",
    "consistency_checks(df_survey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will correct the inconsistencies based on available information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of households where all demographic information is missing: 0\n",
      "\n",
      "Consistency Checks After Corrections:\n",
      "Consistency Checks:\n",
      "Households where size != sum of male and female occupants: 0\n",
      "Households where size != sum of children and adults: 0\n",
      "Households where sum of genders != sum of age groups: 0\n",
      "Households where no adults: 0\n",
      "Households where more than 8 members: 0\n",
      "Households where more children than total size: 0\n",
      "Households where all members are children: 0\n",
      "\n",
      "Detailed information for inconsistent households:\n",
      "Empty DataFrame\n",
      "Columns: [Household_id, household_size, male_occupants, female_occupants, count_children, count_adult]\n",
      "Index: []\n",
      "\n",
      "Summary statistics after corrections:\n",
      "       household_size  male_occupants  female_occupants  count_children  \\\n",
      "count      608.000000      608.000000        608.000000      608.000000   \n",
      "mean         1.922697        0.978618          0.944079        0.161184   \n",
      "std          1.035901        0.747012          0.700786        0.510522   \n",
      "min          1.000000        0.000000          0.000000        0.000000   \n",
      "25%          1.000000        1.000000          1.000000        0.000000   \n",
      "50%          2.000000        1.000000          1.000000        0.000000   \n",
      "75%          2.000000        1.000000          1.000000        0.000000   \n",
      "max          6.000000        4.000000          4.000000        3.000000   \n",
      "\n",
      "       count_adult  \n",
      "count   608.000000  \n",
      "mean      1.761513  \n",
      "std       0.847925  \n",
      "min       1.000000  \n",
      "25%       1.000000  \n",
      "50%       2.000000  \n",
      "75%       2.000000  \n",
      "max       6.000000  \n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of male participants for later imputation\n",
    "male_proportion = df_survey['male_occupants'].sum() / (df_survey['male_occupants'].sum() + df_survey['female_occupants'].sum())\n",
    "\n",
    "# Get most common age range\n",
    "most_common_age = most_common_age_range(df_survey)\n",
    "\n",
    "# Function to correct demographics information based on available information\n",
    "def correct_demographics(row, male_prop):\n",
    "    size = row['household_size']\n",
    "    gender_count = row['male_occupants'] + row['female_occupants']\n",
    "    age_count = row['count_children'] + row['count_adult']\n",
    "    \n",
    "    # If all counts are consistent, return the row as is\n",
    "    if pd.notna(size) and size == gender_count == age_count:\n",
    "        return row\n",
    "    \n",
    "    # Impute missing values based on available data\n",
    "    if pd.notna(size):\n",
    "        if gender_count == 0 and age_count == 0:\n",
    "            # If both gender and age counts are missing, estimate them based on household size\n",
    "            row['male_occupants'] = round(size * male_prop)\n",
    "            row['female_occupants'] = size - row['male_occupants']\n",
    "            row['count_adult'] = size if most_common_age in adult_age_ranges else 0\n",
    "            row['count_children'] = size - row['count_adult']\n",
    "        elif age_count == 0:\n",
    "            # If age count is missing, estimate it based on household size\n",
    "            row['count_adult'] = size if most_common_age in adult_age_ranges else 0\n",
    "            row['count_children'] = size - row['count_adult']\n",
    "        elif gender_count == 0:\n",
    "            # If gender count is missing, estimate it based on household size\n",
    "            row['male_occupants'] = round(size * male_prop)\n",
    "            row['female_occupants'] = size - row['male_occupants']\n",
    "    elif pd.isna(size):\n",
    "        if gender_count > 0 and age_count == 0:\n",
    "            # If household size and age count are missing, estimate them based on gender count\n",
    "            row['household_size'] = gender_count\n",
    "            row['count_adult'] = gender_count if most_common_age in adult_age_ranges else 0\n",
    "            row['count_children'] = gender_count - row['count_adult']\n",
    "        elif gender_count == 0 and age_count > 0:\n",
    "            # If household size and gender count are missing, estimate them based on age count\n",
    "            row['household_size'] = age_count\n",
    "            row['male_occupants'] = round(age_count * male_prop)\n",
    "            row['female_occupants'] = age_count - row['male_occupants']\n",
    "        elif gender_count > 0 and age_count > 0:\n",
    "            # If household size is missing, estimate it based on the maximum of gender and age counts\n",
    "            row['household_size'] = max(gender_count, age_count)\n",
    "    \n",
    "    # Ensure counts do not exceed household size\n",
    "    row['household_size'] = max(row['household_size'], gender_count, age_count)\n",
    "    row['male_occupants'] = min(row['male_occupants'], row['household_size'])\n",
    "    row['female_occupants'] = row['household_size'] - row['male_occupants']\n",
    "    row['count_adult'] = min(row['count_adult'], row['household_size'])\n",
    "    row['count_children'] = row['household_size'] - row['count_adult']\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Apply demographic corrections to each row\n",
    "df_survey = df_survey.apply(lambda row: correct_demographics(row, male_proportion), axis=1)\n",
    "\n",
    "# Function to check if all demographic information is missing\n",
    "def all_demo_missing(row):\n",
    "    return (pd.isna(row['household_size']) and \n",
    "            all(pd.isna(row[col]) for col in gender_columns) and \n",
    "            all(pd.isna(row[col]) for col in age_columns))\n",
    "\n",
    "# Count households where all demographic information is missing\n",
    "all_missing = df_survey[df_survey.apply(all_demo_missing, axis=1)]\n",
    "print(f\"Number of households where all demographic information is missing: {len(all_missing)}\")\n",
    "\n",
    "# Rerun consistency checks after corrections\n",
    "print(\"\\nConsistency Checks After Corrections:\")\n",
    "consistency_checks(df_survey)\n",
    "\n",
    "# Print summary statistics after corrections\n",
    "print(\"\\nSummary statistics after corrections:\")\n",
    "print(df_survey[['household_size', 'male_occupants', 'female_occupants', 'count_children', 'count_adult']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now process the remaining items (Q35-Q135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise merge_columns list and append demographic columns to merge_columns\n",
    "merge_columns = ['Household_id']\n",
    "merge_columns.extend(['household_size', 'male_occupants', 'female_occupants', 'count_children', 'count_adult'])\n",
    "\n",
    "# Q35: Process home ownership status\n",
    "df_survey['ownership_type'] = np.where(df_survey['Q35'].str.contains('outright|mortgage', case=False, na=False), 'owned',\n",
    "                               np.where(df_survey['Q35'].str.contains('rent|landlord|local authority', case=False, na=False), 'rented',\n",
    "                               np.where(df_survey['Q35'].notna(), 'other', np.nan)))\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "most_frequent_ownership = df_survey['ownership_type'].mode()[0]\n",
    "df_survey['ownership_type'] = df_survey['ownership_type'].fillna(most_frequent_ownership)\n",
    "\n",
    "# Create dummy variables for ownership type\n",
    "for ownership in ['owned', 'rented', 'other']:\n",
    "    df_survey[f'ownership_{ownership}'] = (df_survey['ownership_type'] == ownership).astype(int)\n",
    "    merge_columns.append(f'ownership_{ownership}')\n",
    "\n",
    "# Q36: Process work from home\n",
    "work_from_home_map = {'Never': 0, 'Occasionally': 1, 'About half the time': 2, 'Most/all weekdays': 3}\n",
    "df_survey['work_from_home'] = df_survey['Q36'].map(work_from_home_map)\n",
    "merge_columns.append('work_from_home')\n",
    "\n",
    "# Q37-Q39: Process housing type\n",
    "df_survey['housing_type'] = np.where(df_survey['Q37'].notna(), 'house',\n",
    "                              np.where(df_survey['Q38'].notna(), 'apartment',\n",
    "                              np.where(df_survey['Q39'].notna(), 'mobile', np.nan)))\n",
    "\n",
    "# Impute missing values with the most frequent value\n",
    "most_frequent_housing = df_survey['housing_type'].mode()[0]\n",
    "df_survey['housing_type'] = df_survey['housing_type'].fillna(most_frequent_housing)\n",
    "\n",
    "# Create dummy variables for housing type\n",
    "for housing in ['house', 'apartment', 'mobile']:\n",
    "    df_survey[f'housing_{housing}'] = (df_survey['housing_type'] == housing).astype(int)\n",
    "    merge_columns.append(f'housing_{housing}')\n",
    "\n",
    "# Q40-Q41: Process number of rooms and bedrooms\n",
    "df_survey['count_rooms'] = pd.to_numeric(df_survey['Q40'], errors='coerce')\n",
    "df_survey['count_bedrooms'] = pd.to_numeric(df_survey['Q41'], errors='coerce')\n",
    "merge_columns.extend(['count_rooms', 'count_bedrooms'])\n",
    "\n",
    "# Q42-Q46: Process insulation\n",
    "insulation_types = ['Double glazing', 'Roof or loft insulation', 'Wall insulation', \n",
    "                    'Floor insulation', 'Hot water tank insulation/lagging']\n",
    "\n",
    "for i, insulation in enumerate(insulation_types):\n",
    "    question = f'Q{i+42}'\n",
    "    col_name = f'insulation_{insulation.lower().replace(\" \", \"_\").replace(\"/\", \"_\")}'\n",
    "    df_survey[col_name] = df_survey[question].map({'Yes': 1, 'No': 0, \"Don't know\": np.nan})\n",
    "    merge_columns.append(col_name)\n",
    "\n",
    "# Q47: Process central heating type\n",
    "df_survey['electric_central_heating'] = df_survey['Q47'].apply(lambda x: 1 if 'Electric' in str(x) else (0 if pd.notna(x) and 'Don\\'t know' not in str(x) else np.nan))\n",
    "merge_columns.append('electric_central_heating')\n",
    "\n",
    "# Q48: Process central heating usage\n",
    "heating_controls = [\n",
    "    'manual_boiler',\n",
    "    'thermostatic_valves',\n",
    "    'auto_set_times',\n",
    "    'auto_temp_control',\n",
    "    'not_sure'\n",
    "]\n",
    "\n",
    "control_phrases = [\n",
    "    'I switch the heating on manually at the boiler when needed',\n",
    "    'I control the room temperature using the thermostatic valves on the radiator',\n",
    "    'The heating switches on and off automatically at set times of the day',\n",
    "    'The heating is controlled automatically by a thermostatic temperature control',\n",
    "    \"I'm not sure how it is controlled/used\"\n",
    "]\n",
    "\n",
    "for control, phrase in zip(heating_controls, control_phrases):\n",
    "    col_name = f'heating_{control}'\n",
    "    df_survey[col_name] = df_survey['Q48'].str.contains(phrase, na=False).astype(int)\n",
    "    merge_columns.append(col_name)\n",
    "\n",
    "# Q49: Process water heating\n",
    "df_survey['uses_electric_heater'] = df_survey['Q49'].apply(lambda x: 1 if 'electric' in str(x).lower() else (0 if pd.notna(x) and 'Don\\'t know' not in str(x) else np.nan))\n",
    "merge_columns.append('uses_electric_heater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q50-Q79: Process light bulb counts\n",
    "bulb_types = {\n",
    "    'low_efficiency': list(range(50, 56)) + list(range(62, 68)),  # Traditional and halogen bulbs\n",
    "    'high_efficiency': list(range(56, 62)) + list(range(68, 74)),  # Low energy and LED\n",
    "    'fluorescent_tubes': range(74, 80)\n",
    "}\n",
    "\n",
    "# Process each bulb type\n",
    "for bulb_type, question_range in bulb_types.items():\n",
    "    if bulb_type == 'fluorescent_tubes':\n",
    "        col_name = f'count_{bulb_type}'\n",
    "    else:\n",
    "        col_name = f'count_{bulb_type}_bulbs'\n",
    "    # Sum the counts for each bulb type\n",
    "    df_survey[col_name] = df_survey[[f'Q{i}' for i in question_range]].sum(axis=1)\n",
    "    merge_columns.append(col_name)\n",
    "\n",
    "# Q80-93: Process refrigeration appliances\n",
    "fridge_sizes = [1, 2, 3, 3.5]  # Relative sizes for fridges\n",
    "freezer_sizes = [2.5, 3.5, 1.5, 2.5, 3.5, 4.5]  # Relative sizes for freezers\n",
    "fridge_freezer_sizes = [2.25, 3.25, 4.25, 5.25]  # Relative sizes for fridge-freezers\n",
    "\n",
    "def calculate_total_refrigeration_units(row):\n",
    "    fridge_total = sum(count * size for count, size in zip([row[f'Q{i}'] for i in range(80, 84)], fridge_sizes))\n",
    "    freezer_total = sum(count * size for count, size in zip([row[f'Q{i}'] for i in range(84, 90)], freezer_sizes))\n",
    "    fridge_freezer_total = sum(count * size for count, size in zip([row[f'Q{i}'] for i in range(90, 94)], fridge_freezer_sizes))\n",
    "    return fridge_total + freezer_total + fridge_freezer_total\n",
    "\n",
    "df_survey['total_refrigeration_units'] = df_survey.apply(calculate_total_refrigeration_units, axis=1)\n",
    "merge_columns.append('total_refrigeration_units')\n",
    "\n",
    "# Also calculate the count of each type\n",
    "df_survey['fridge_count'] = df_survey[[f'Q{i}' for i in range(80, 84)]].sum(axis=1)\n",
    "df_survey['freezer_count'] = df_survey[[f'Q{i}' for i in range(84, 90)]].sum(axis=1)\n",
    "df_survey['fridge_freezer_count'] = df_survey[[f'Q{i}' for i in range(90, 94)]].sum(axis=1)\n",
    "df_survey['count_fridges_and_freezers'] = df_survey['fridge_count'] + df_survey['freezer_count'] + df_survey['fridge_freezer_count']\n",
    "merge_columns.append('count_fridges_and_freezers')\n",
    "\n",
    "# Q94-Q115: Process other appliance counts\n",
    "appliance_groups = {\n",
    "    'cooking_appliances': ['Q94', 'Q95', 'Q96', 'Q97'],  # Electric hob, Gas hob, Electric oven, Microwave\n",
    "    'laundry_appliances': ['Q98', 'Q99', 'Q100'],  # Washing machine, Tumble dryer, Washer-dryer\n",
    "    'kitchen_appliances': ['Q101'],  # Dishwasher\n",
    "    'heating_water_appliances': ['Q102', 'Q103', 'Q104'],  # Electric shower, Over-sink electric water heater, Portable electric heater\n",
    "    'entertainment_devices': ['Q105', 'Q110', 'Q111', 'Q112', 'Q113', 'Q114'],  # TV, DVD player, Cable TV box, Satellite TV box, Freeview TV box, Games console\n",
    "    'computing_devices': ['Q106', 'Q107', 'Q108', 'Q109'],  # Desktop PC, Laptop, Printer, Router\n",
    "    'energy_saving_devices': ['Q115']  # Standby savers\n",
    "}\n",
    "\n",
    "for group, questions in appliance_groups.items():\n",
    "    col_name = f'count_{group}'\n",
    "    df_survey[col_name] = df_survey[questions].sum(axis=1)\n",
    "    merge_columns.append(col_name)\n",
    "\n",
    "# Process TV information (Q116-Q127)\n",
    "def tv_energy_score(tv_type, tv_size):\n",
    "    type_score = {'Traditional/older style (CRT)': 3, 'LED': 1, 'LCD': 2, 'Plasma': 4, 'Other': 2.5}\n",
    "    size_score = {'24 inches or less': 1, '25 to 32 inches': 2, '33 to 49 inches': 3, '50 inches or more': 4}\n",
    "    \n",
    "    tv_type = str(tv_type) if pd.notna(tv_type) else ''\n",
    "    tv_size = str(tv_size) if pd.notna(tv_size) else ''\n",
    "    \n",
    "    return type_score.get(tv_type, 0) * size_score.get(tv_size, 0)\n",
    "\n",
    "tv_types = [f'Q{i}' for i in range(116, 122)]\n",
    "tv_sizes = [f'Q{i}' for i in range(122, 128)]\n",
    "\n",
    "df_survey['count_tv'] = df_survey[tv_types].notna().sum(axis=1)\n",
    "df_survey['tv_energy_score'] = sum(df_survey.apply(lambda row: tv_energy_score(row[type_col], row[size_col]), axis=1) \n",
    "                                   for type_col, size_col in zip(tv_types, tv_sizes))\n",
    "\n",
    "merge_columns.extend(['count_tv', 'tv_energy_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q128-Q129: Process smart meter views and usage\n",
    "# Questions about other household members' observed behavior have nearly half the responses missing, so they have been omitted.\n",
    "smart_meter_questions = ['Q128', 'Q129']\n",
    "\n",
    "def map_frequency(x):\n",
    "    mapping = {\n",
    "        'Never': 0,\n",
    "        'Less often than once a week': 1,\n",
    "        'About once a week': 2,\n",
    "        'Every 4-5 days': 3,\n",
    "        'Every 2-3 days': 4,\n",
    "        'At least once every day': 5,\n",
    "        'Several times every day': 6\n",
    "    }\n",
    "    return mapping.get(x, np.nan)\n",
    "\n",
    "for question in smart_meter_questions:\n",
    "    df_survey[f'{question}_encoded'] = df_survey[question].apply(map_frequency)\n",
    "\n",
    "df_survey['smart_meter_interaction_score'] = df_survey[[f'{q}_encoded' for q in smart_meter_questions]].mean(axis=1)\n",
    "merge_columns.append('smart_meter_interaction_score')\n",
    "\n",
    "# Q130-Q131: Process interest in renewable energy and microgeneration\n",
    "interest_questions = {'Q130': 'renewable_energy', 'Q131': 'microgeneration'}\n",
    "\n",
    "def map_interest(x):\n",
    "    mapping = {\n",
    "        'Not at all interested': 0,\n",
    "        'Not very interested': 1,\n",
    "        \"don't know/haven't thought about it\": 2,\n",
    "        'Fairly interested': 3,\n",
    "        'Very interested': 4\n",
    "    }\n",
    "    return mapping.get(x, np.nan)\n",
    "\n",
    "for question, interest_type in interest_questions.items():\n",
    "    col_name = f'interest_in_{interest_type}'\n",
    "    df_survey[col_name] = df_survey[question].apply(map_interest)\n",
    "    merge_columns.append(col_name)\n",
    "\n",
    "# Q132: Process concern about climate change\n",
    "climate_concern_map = {\n",
    "    'Not at all concerned': 0,\n",
    "    'Not very concerned': 1,\n",
    "    \"don't know/No opinion\": 2,\n",
    "    'Fairly concerned': 3,\n",
    "    'Very concerned': 4\n",
    "}\n",
    "\n",
    "df_survey['climate_change_concern'] = df_survey['Q132'].map(climate_concern_map)\n",
    "merge_columns.append('climate_change_concern')\n",
    "\n",
    "# Q133: Process lifestyle and environment statement\n",
    "lifestyle_environment_map = {\n",
    "    'I\\'d like to do a lot more to help the environment': 2,\n",
    "    'I\\'d like to do a bit more to help the environment': 1,\n",
    "    'I\\'m happy with what I do at the moment': 0\n",
    "}\n",
    "df_survey['lifestyle_environment'] = df_survey['Q133'].map(lifestyle_environment_map)\n",
    "merge_columns.append('lifestyle_environment')\n",
    "\n",
    "# Q134-Q135: Process helpfulness of smart meter for understanding bill and consumption\n",
    "def map_helpfulness(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    mapping = {\n",
    "        'Not at all helpful': 0,\n",
    "        'Not very helpful': 1,\n",
    "        'Have not thought about it': 2,\n",
    "        'don\\'t know': 2,\n",
    "        'Fairly helpful': 3,\n",
    "        'Very helpful': 4\n",
    "    }\n",
    "    return mapping.get(x, np.nan)\n",
    "\n",
    "df_survey['smart_meter_bill_understanding'] = df_survey['Q134'].apply(map_helpfulness)\n",
    "df_survey['smart_meter_consumption_understanding'] = df_survey['Q135'].apply(map_helpfulness)\n",
    "merge_columns.extend(['smart_meter_bill_understanding', 'smart_meter_consumption_understanding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the output file from part 3 (attitudes survey)\n",
    "df_consumption = pd.read_csv('3) household_energy_consumption_with_attitudinal_features.csv')\n",
    "\n",
    "# Merge with the energy consumption data\n",
    "df_merged = pd.merge(df_consumption, df_survey[merge_columns], \n",
    "                    left_on='household_id', right_on='Household_id', how='inner')\n",
    "\n",
    "# Drop the redundant Household_id column\n",
    "df_merged = df_merged.drop('Household_id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will now create a final dataset that has consumption data, tariff data, weather data, as well as household data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before merging:\n",
      "Survey data shape: (5326080, 72)\n",
      "Weather data shape: (8760, 6)\n",
      "Unique timestamps in survey data: 8760\n",
      "Unique timestamps in weather data: 8760\n",
      "\n",
      "After merging:\n",
      "Merged data shape: (5325472, 77)\n",
      "Unique timestamps in merged data: 8759\n",
      "timestamp                                        object\n",
      "household_id                                     object\n",
      "consumption                                     float64\n",
      "tariff                                          float64\n",
      "washing_machine_fixed_schedule                  float64\n",
      "tumble_dryer_fixed_schedule                     float64\n",
      "dishwasher_fixed_schedule                       float64\n",
      "immersion_water_heater_fixed_schedule           float64\n",
      "electric_oven_fixed_schedule                    float64\n",
      "electric_hob_fixed_schedule                     float64\n",
      "ironing_fixed_schedule                          float64\n",
      "electric_shower_fixed_schedule                  float64\n",
      "kettle_fixed_schedule                           float64\n",
      "lighting_fixed_schedule                         float64\n",
      "electric_heater_fixed_schedule                  float64\n",
      "washer-dryer_combined_timer_use                 float64\n",
      "washing_machine_timer_use                       float64\n",
      "tumble_dryer_timer_use                          float64\n",
      "dishwasher_timer_use                            float64\n",
      "electric_space_heating_timer_use                float64\n",
      "washer-dryer_combined_ownership                 float64\n",
      "washing_machine_ownership                       float64\n",
      "tumble_dryer_ownership                          float64\n",
      "dishwasher_ownership                            float64\n",
      "electric_space_heating_ownership                float64\n",
      "household_size                                  float64\n",
      "male_occupants                                    int64\n",
      "female_occupants                                float64\n",
      "count_children                                  float64\n",
      "count_adult                                     float64\n",
      "ownership_owned                                   int32\n",
      "ownership_rented                                  int32\n",
      "ownership_other                                   int32\n",
      "work_from_home                                  float64\n",
      "housing_house                                     int32\n",
      "housing_apartment                                 int32\n",
      "housing_mobile                                    int32\n",
      "count_rooms                                     float64\n",
      "count_bedrooms                                  float64\n",
      "insulation_double_glazing                       float64\n",
      "insulation_roof_or_loft_insulation              float64\n",
      "insulation_wall_insulation                      float64\n",
      "insulation_floor_insulation                     float64\n",
      "insulation_hot_water_tank_insulation_lagging    float64\n",
      "electric_central_heating                        float64\n",
      "heating_manual_boiler                             int32\n",
      "heating_thermostatic_valves                       int32\n",
      "heating_auto_set_times                            int32\n",
      "heating_auto_temp_control                         int32\n",
      "heating_not_sure                                  int32\n",
      "uses_electric_heater                            float64\n",
      "count_low_efficiency_bulbs                      float64\n",
      "count_high_efficiency_bulbs                     float64\n",
      "count_fluorescent_tubes                         float64\n",
      "total_refrigeration_units                       float64\n",
      "count_fridges_and_freezers                      float64\n",
      "count_cooking_appliances                        float64\n",
      "count_laundry_appliances                        float64\n",
      "count_kitchen_appliances                        float64\n",
      "count_heating_water_appliances                  float64\n",
      "count_entertainment_devices                     float64\n",
      "count_computing_devices                         float64\n",
      "count_energy_saving_devices                     float64\n",
      "count_tv                                          int64\n",
      "tv_energy_score                                 float64\n",
      "smart_meter_interaction_score                   float64\n",
      "interest_in_renewable_energy                    float64\n",
      "interest_in_microgeneration                     float64\n",
      "climate_change_concern                          float64\n",
      "lifestyle_environment                           float64\n",
      "smart_meter_bill_understanding                  float64\n",
      "smart_meter_consumption_understanding           float64\n",
      "solarradiation                                  float64\n",
      "windspeed                                       float64\n",
      "temp                                            float64\n",
      "precip                                          float64\n",
      "humidity                                        float64\n",
      "dtype: object\n",
      "\n",
      "Final merged dataframe has been exported to '4) final_merged_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data to merge it with df_merged\n",
    "df_weather = pd.read_csv('1b) merged_weather_data.csv')\n",
    "\n",
    "# Print information before merging\n",
    "print(\"Before merging:\")\n",
    "print(f\"Survey data shape: {df_merged.shape}\")\n",
    "print(f\"Weather data shape: {df_weather.shape}\")\n",
    "print(f\"Unique timestamps in survey data: {df_merged['timestamp'].nunique()}\")\n",
    "print(f\"Unique timestamps in weather data: {df_weather['datetime'].nunique()}\")\n",
    "\n",
    "# Merge the dataframes\n",
    "df_final_merged = pd.merge(df_merged, df_weather, \n",
    "                     left_on='timestamp', \n",
    "                     right_on='datetime', \n",
    "                     how='inner')\n",
    "\n",
    "# Drop the redundant datetime column\n",
    "df_final_merged = df_final_merged.drop('datetime', axis=1)\n",
    "\n",
    "# Print information after merging\n",
    "print(\"\\nAfter merging:\")\n",
    "print(f\"Merged data shape: {df_final_merged.shape}\")\n",
    "print(f\"Unique timestamps in merged data: {df_final_merged['timestamp'].nunique()}\")\n",
    "\n",
    "# Print data types of the merged dataframe\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(df_final_merged.dtypes)\n",
    "pd.reset_option('display.max_rows')\n",
    "\n",
    "# Export the final merged dataframe to a CSV file\n",
    "df_final_merged.to_csv('4) final_merged_data.csv', index=False)\n",
    "print(\"\\nFinal merged dataframe has been exported to '4) final_merged_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both datasets, before merging, had the same number of timestamps, let's look at why we lost one timestamp after merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in timestamps: {'2013-01-01 00:00:00', '2014-01-01 00:00:00'}\n"
     ]
    }
   ],
   "source": [
    "survey_timestamps = set(df_merged['timestamp'])\n",
    "weather_timestamps = set(df_weather['datetime'])\n",
    "\n",
    "difference_in_timestamps = survey_timestamps.symmetric_difference(weather_timestamps)\n",
    "\n",
    "if difference_in_timestamps:\n",
    "    print(f\"Difference in timestamps: {difference_in_timestamps}\")\n",
    "else:\n",
    "    print(\"No differences in timestamps between survey and weather data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems each dataset had a unique timestamp, which is not a problem. We now have a merged dataset whose timestamp starts at 2013-1-1 01:00:00 and ends at 2013-12-31 23:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First timestamp in merged dataset: 2013-01-01 01:00:00\n",
      "Last timestamp in merged dataset: 2013-12-31 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check the first and last timestamp of the merged dataset\n",
    "first_timestamp = df_final_merged['timestamp'].min()\n",
    "last_timestamp = df_final_merged['timestamp'].max()\n",
    "\n",
    "print(f\"First timestamp in merged dataset: {first_timestamp}\")\n",
    "print(f\"Last timestamp in merged dataset: {last_timestamp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
